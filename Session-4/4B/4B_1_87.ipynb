{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4B_1.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1pFn0wvWOKj93A4_-pjMxsxR96VDyN-NF",
          "timestamp": 1527345591944
        },
        {
          "file_id": "1_1kwmwgL7g94jI6BEtcgm-D2_AFk0zxK",
          "timestamp": 1519101209834
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a56560c-d4f1-4a7d-de8f-6cf012bfbfd9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527510942943,
          "user_tz": -330,
          "elapsed": 4069,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lJT2mLzKNqno",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Linking drive to colab to store datasets\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zC_f-TGfOFva",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XaElmk35OF2T",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library. Though the link asks you to verify twice, you don't have to!\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3NZ8qV9OFzl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print ('Files in Drive:')\n",
        "!ls drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CzVhrP6IO0-9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c0718244-c55b-45a4-b48c-54bb6c2d3f08",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527511423660,
          "user_tz": -330,
          "elapsed": 112218,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a file in a new directory called \"Kaggle\" in your Google Drive. This will be your operation base :P\n",
        "#!echo \"This newly created file will appear in your Drive file list. If you are reading this, that means the attempt to integrate was successful\" > drive/EIP/created.txt\n",
        "!cp -r drive/EIP/* .\n",
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attempt_1\t\t\t  weights-improvement-30-0.85.hdf5\r\n",
            "datalab\t\t\t\t  weights-improvement-30-0.86.hdf5\r\n",
            "DNST_model.h5\t\t\t  weights-improvement-31-0.87.hdf5\r\n",
            "drive\t\t\t\t  weights-improvement-33-0.86.hdf5\r\n",
            "weights-improvement-25-0.84.hdf5  weights-improvement-39-0.87.hdf5\r\n",
            "weights-improvement-26-0.83.hdf5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#For architecture\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#For loading models\n",
        "from pathlib import Path\n",
        "from keras.models import load_model\n",
        "\n",
        "#For data augmentation\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "21ae245c-e770-498d-9f18-16ac52b2d82a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527511460122,
          "user_tz": -330,
          "elapsed": 33152,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 29s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.3):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_filter = 80\n",
        "dropout_rate = 0.4\n",
        "l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (5,5), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 10439
        },
        "outputId": "89d2b4a6-8dbc-4e39-df77-0d238b749e8d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527520338848,
          "user_tz": -330,
          "elapsed": 874,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 32, 32, 80)   6000        input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 32, 32, 80)   320         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 32, 32, 80)   0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 32, 32, 40)   28800       activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_256 (Dropout)           (None, 32, 32, 40)   0           conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_241 (Concatenate)   (None, 32, 32, 120)  0           conv2d_261[0][0]                 \n",
            "                                                                 dropout_256[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 32, 32, 120)  480         concatenate_241[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 32, 32, 120)  0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 32, 32, 40)   43200       activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_257 (Dropout)           (None, 32, 32, 40)   0           conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_242 (Concatenate)   (None, 32, 32, 160)  0           concatenate_241[0][0]            \n",
            "                                                                 dropout_257[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 32, 32, 160)  640         concatenate_242[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 32, 32, 160)  0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 32, 32, 40)   57600       activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_258 (Dropout)           (None, 32, 32, 40)   0           conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_243 (Concatenate)   (None, 32, 32, 200)  0           concatenate_242[0][0]            \n",
            "                                                                 dropout_258[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 32, 32, 200)  800         concatenate_243[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 32, 32, 200)  0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 32, 32, 40)   72000       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_259 (Dropout)           (None, 32, 32, 40)   0           conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_244 (Concatenate)   (None, 32, 32, 240)  0           concatenate_243[0][0]            \n",
            "                                                                 dropout_259[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 32, 32, 240)  960         concatenate_244[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 32, 32, 240)  0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 32, 32, 40)   86400       activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_260 (Dropout)           (None, 32, 32, 40)   0           conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_245 (Concatenate)   (None, 32, 32, 280)  0           concatenate_244[0][0]            \n",
            "                                                                 dropout_260[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 32, 32, 280)  1120        concatenate_245[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 32, 32, 280)  0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 32, 32, 40)   100800      activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_261 (Dropout)           (None, 32, 32, 40)   0           conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_246 (Concatenate)   (None, 32, 32, 320)  0           concatenate_245[0][0]            \n",
            "                                                                 dropout_261[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 32, 32, 320)  1280        concatenate_246[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 32, 32, 320)  0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 32, 32, 40)   115200      activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_262 (Dropout)           (None, 32, 32, 40)   0           conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_247 (Concatenate)   (None, 32, 32, 360)  0           concatenate_246[0][0]            \n",
            "                                                                 dropout_262[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 32, 32, 360)  1440        concatenate_247[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 32, 32, 360)  0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 32, 32, 40)   129600      activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_263 (Dropout)           (None, 32, 32, 40)   0           conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_248 (Concatenate)   (None, 32, 32, 400)  0           concatenate_247[0][0]            \n",
            "                                                                 dropout_263[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 32, 32, 400)  1600        concatenate_248[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 32, 32, 400)  0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 32, 32, 40)   144000      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_264 (Dropout)           (None, 32, 32, 40)   0           conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_249 (Concatenate)   (None, 32, 32, 440)  0           concatenate_248[0][0]            \n",
            "                                                                 dropout_264[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 32, 32, 440)  1760        concatenate_249[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 32, 32, 440)  0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 32, 32, 40)   158400      activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_265 (Dropout)           (None, 32, 32, 40)   0           conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_250 (Concatenate)   (None, 32, 32, 480)  0           concatenate_249[0][0]            \n",
            "                                                                 dropout_265[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 32, 32, 480)  1920        concatenate_250[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 32, 32, 480)  0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 32, 32, 40)   172800      activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_266 (Dropout)           (None, 32, 32, 40)   0           conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_251 (Concatenate)   (None, 32, 32, 520)  0           concatenate_250[0][0]            \n",
            "                                                                 dropout_266[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 32, 32, 520)  2080        concatenate_251[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 32, 32, 520)  0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 32, 32, 40)   187200      activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_267 (Dropout)           (None, 32, 32, 40)   0           conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_252 (Concatenate)   (None, 32, 32, 560)  0           concatenate_251[0][0]            \n",
            "                                                                 dropout_267[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 32, 32, 560)  2240        concatenate_252[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 32, 32, 560)  0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 32, 32, 40)   22400       activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_268 (Dropout)           (None, 32, 32, 40)   0           conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 16, 16, 40)   0           dropout_268[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 16, 16, 40)   160         average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 16, 16, 40)   0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 16, 16, 40)   14400       activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_269 (Dropout)           (None, 16, 16, 40)   0           conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_253 (Concatenate)   (None, 16, 16, 80)   0           average_pooling2d_21[0][0]       \n",
            "                                                                 dropout_269[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 16, 16, 80)   320         concatenate_253[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 16, 16, 80)   0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 16, 16, 40)   28800       activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_270 (Dropout)           (None, 16, 16, 40)   0           conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_254 (Concatenate)   (None, 16, 16, 120)  0           concatenate_253[0][0]            \n",
            "                                                                 dropout_270[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 16, 16, 120)  480         concatenate_254[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 16, 16, 120)  0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 16, 16, 40)   43200       activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_271 (Dropout)           (None, 16, 16, 40)   0           conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_255 (Concatenate)   (None, 16, 16, 160)  0           concatenate_254[0][0]            \n",
            "                                                                 dropout_271[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 16, 16, 160)  640         concatenate_255[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 16, 16, 160)  0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 16, 16, 40)   57600       activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_272 (Dropout)           (None, 16, 16, 40)   0           conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_256 (Concatenate)   (None, 16, 16, 200)  0           concatenate_255[0][0]            \n",
            "                                                                 dropout_272[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 16, 16, 200)  800         concatenate_256[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 16, 16, 200)  0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 16, 16, 40)   72000       activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_273 (Dropout)           (None, 16, 16, 40)   0           conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_257 (Concatenate)   (None, 16, 16, 240)  0           concatenate_256[0][0]            \n",
            "                                                                 dropout_273[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 16, 16, 240)  960         concatenate_257[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 16, 16, 240)  0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 16, 16, 40)   86400       activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_274 (Dropout)           (None, 16, 16, 40)   0           conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_258 (Concatenate)   (None, 16, 16, 280)  0           concatenate_257[0][0]            \n",
            "                                                                 dropout_274[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 16, 16, 280)  1120        concatenate_258[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 16, 16, 280)  0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 16, 16, 40)   100800      activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_275 (Dropout)           (None, 16, 16, 40)   0           conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_259 (Concatenate)   (None, 16, 16, 320)  0           concatenate_258[0][0]            \n",
            "                                                                 dropout_275[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 16, 16, 320)  1280        concatenate_259[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 16, 16, 320)  0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 16, 16, 40)   115200      activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_276 (Dropout)           (None, 16, 16, 40)   0           conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_260 (Concatenate)   (None, 16, 16, 360)  0           concatenate_259[0][0]            \n",
            "                                                                 dropout_276[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 16, 16, 360)  1440        concatenate_260[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 16, 16, 360)  0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 16, 16, 40)   129600      activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_277 (Dropout)           (None, 16, 16, 40)   0           conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_261 (Concatenate)   (None, 16, 16, 400)  0           concatenate_260[0][0]            \n",
            "                                                                 dropout_277[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 16, 16, 400)  1600        concatenate_261[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 16, 16, 400)  0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 16, 16, 40)   144000      activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_278 (Dropout)           (None, 16, 16, 40)   0           conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_262 (Concatenate)   (None, 16, 16, 440)  0           concatenate_261[0][0]            \n",
            "                                                                 dropout_278[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 16, 16, 440)  1760        concatenate_262[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 16, 16, 440)  0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 16, 16, 40)   158400      activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_279 (Dropout)           (None, 16, 16, 40)   0           conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_263 (Concatenate)   (None, 16, 16, 480)  0           concatenate_262[0][0]            \n",
            "                                                                 dropout_279[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 16, 16, 480)  1920        concatenate_263[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 16, 16, 480)  0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 16, 16, 40)   172800      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_280 (Dropout)           (None, 16, 16, 40)   0           conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_264 (Concatenate)   (None, 16, 16, 520)  0           concatenate_263[0][0]            \n",
            "                                                                 dropout_280[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 16, 16, 520)  2080        concatenate_264[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 16, 16, 520)  0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 16, 16, 40)   20800       activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_281 (Dropout)           (None, 16, 16, 40)   0           conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 8, 8, 40)     0           dropout_281[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 8, 8, 40)     160         average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 8, 8, 40)     0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 8, 8, 40)     14400       activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_282 (Dropout)           (None, 8, 8, 40)     0           conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_265 (Concatenate)   (None, 8, 8, 80)     0           average_pooling2d_22[0][0]       \n",
            "                                                                 dropout_282[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 8, 8, 80)     320         concatenate_265[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 8, 8, 80)     0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 8, 8, 40)     28800       activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_283 (Dropout)           (None, 8, 8, 40)     0           conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_266 (Concatenate)   (None, 8, 8, 120)    0           concatenate_265[0][0]            \n",
            "                                                                 dropout_283[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 8, 8, 120)    480         concatenate_266[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 8, 8, 120)    0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 8, 8, 40)     43200       activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_284 (Dropout)           (None, 8, 8, 40)     0           conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_267 (Concatenate)   (None, 8, 8, 160)    0           concatenate_266[0][0]            \n",
            "                                                                 dropout_284[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 8, 8, 160)    640         concatenate_267[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 8, 8, 160)    0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 8, 8, 40)     57600       activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_285 (Dropout)           (None, 8, 8, 40)     0           conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_268 (Concatenate)   (None, 8, 8, 200)    0           concatenate_267[0][0]            \n",
            "                                                                 dropout_285[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 8, 8, 200)    800         concatenate_268[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 8, 8, 200)    0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 8, 8, 40)     72000       activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_286 (Dropout)           (None, 8, 8, 40)     0           conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_269 (Concatenate)   (None, 8, 8, 240)    0           concatenate_268[0][0]            \n",
            "                                                                 dropout_286[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 8, 8, 240)    960         concatenate_269[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 8, 8, 240)    0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 8, 8, 40)     86400       activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_287 (Dropout)           (None, 8, 8, 40)     0           conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_270 (Concatenate)   (None, 8, 8, 280)    0           concatenate_269[0][0]            \n",
            "                                                                 dropout_287[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 8, 8, 280)    1120        concatenate_270[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 8, 8, 280)    0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 8, 8, 40)     100800      activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_288 (Dropout)           (None, 8, 8, 40)     0           conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_271 (Concatenate)   (None, 8, 8, 320)    0           concatenate_270[0][0]            \n",
            "                                                                 dropout_288[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 8, 8, 320)    1280        concatenate_271[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 8, 8, 320)    0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 8, 8, 40)     115200      activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_289 (Dropout)           (None, 8, 8, 40)     0           conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_272 (Concatenate)   (None, 8, 8, 360)    0           concatenate_271[0][0]            \n",
            "                                                                 dropout_289[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 8, 8, 360)    1440        concatenate_272[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 8, 8, 360)    0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 8, 8, 40)     129600      activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_290 (Dropout)           (None, 8, 8, 40)     0           conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_273 (Concatenate)   (None, 8, 8, 400)    0           concatenate_272[0][0]            \n",
            "                                                                 dropout_290[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 8, 8, 400)    1600        concatenate_273[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 8, 8, 400)    0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 8, 8, 40)     144000      activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_291 (Dropout)           (None, 8, 8, 40)     0           conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_274 (Concatenate)   (None, 8, 8, 440)    0           concatenate_273[0][0]            \n",
            "                                                                 dropout_291[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 8, 8, 440)    1760        concatenate_274[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 8, 8, 440)    0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 8, 8, 40)     158400      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_292 (Dropout)           (None, 8, 8, 40)     0           conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_275 (Concatenate)   (None, 8, 8, 480)    0           concatenate_274[0][0]            \n",
            "                                                                 dropout_292[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 8, 8, 480)    1920        concatenate_275[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 8, 8, 480)    0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 8, 8, 40)     172800      activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_293 (Dropout)           (None, 8, 8, 40)     0           conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_276 (Concatenate)   (None, 8, 8, 520)    0           concatenate_275[0][0]            \n",
            "                                                                 dropout_293[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 8, 8, 520)    2080        concatenate_276[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 8, 8, 520)    0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 8, 8, 40)     20800       activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_294 (Dropout)           (None, 8, 8, 40)     0           conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 4, 4, 40)     0           dropout_294[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 4, 4, 40)     160         average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 4, 4, 40)     0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 4, 4, 40)     14400       activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_295 (Dropout)           (None, 4, 4, 40)     0           conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_277 (Concatenate)   (None, 4, 4, 80)     0           average_pooling2d_23[0][0]       \n",
            "                                                                 dropout_295[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 4, 4, 80)     320         concatenate_277[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 4, 4, 80)     0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 4, 4, 40)     28800       activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_296 (Dropout)           (None, 4, 4, 40)     0           conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_278 (Concatenate)   (None, 4, 4, 120)    0           concatenate_277[0][0]            \n",
            "                                                                 dropout_296[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 4, 4, 120)    480         concatenate_278[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 4, 4, 120)    0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 4, 4, 40)     43200       activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_297 (Dropout)           (None, 4, 4, 40)     0           conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_279 (Concatenate)   (None, 4, 4, 160)    0           concatenate_278[0][0]            \n",
            "                                                                 dropout_297[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 4, 4, 160)    640         concatenate_279[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 4, 4, 160)    0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 4, 4, 40)     57600       activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_298 (Dropout)           (None, 4, 4, 40)     0           conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_280 (Concatenate)   (None, 4, 4, 200)    0           concatenate_279[0][0]            \n",
            "                                                                 dropout_298[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 4, 4, 200)    800         concatenate_280[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 4, 4, 200)    0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 4, 4, 40)     72000       activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_299 (Dropout)           (None, 4, 4, 40)     0           conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_281 (Concatenate)   (None, 4, 4, 240)    0           concatenate_280[0][0]            \n",
            "                                                                 dropout_299[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 4, 4, 240)    960         concatenate_281[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 4, 4, 240)    0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 4, 4, 40)     86400       activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_300 (Dropout)           (None, 4, 4, 40)     0           conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_282 (Concatenate)   (None, 4, 4, 280)    0           concatenate_281[0][0]            \n",
            "                                                                 dropout_300[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 4, 4, 280)    1120        concatenate_282[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 4, 4, 280)    0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 4, 4, 40)     100800      activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_301 (Dropout)           (None, 4, 4, 40)     0           conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_283 (Concatenate)   (None, 4, 4, 320)    0           concatenate_282[0][0]            \n",
            "                                                                 dropout_301[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 4, 4, 320)    1280        concatenate_283[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 4, 4, 320)    0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 4, 4, 40)     115200      activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_302 (Dropout)           (None, 4, 4, 40)     0           conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_284 (Concatenate)   (None, 4, 4, 360)    0           concatenate_283[0][0]            \n",
            "                                                                 dropout_302[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 4, 4, 360)    1440        concatenate_284[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 4, 4, 360)    0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 4, 4, 40)     129600      activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_303 (Dropout)           (None, 4, 4, 40)     0           conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_285 (Concatenate)   (None, 4, 4, 400)    0           concatenate_284[0][0]            \n",
            "                                                                 dropout_303[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 4, 4, 400)    1600        concatenate_285[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 4, 4, 400)    0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 4, 4, 40)     144000      activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_304 (Dropout)           (None, 4, 4, 40)     0           conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_286 (Concatenate)   (None, 4, 4, 440)    0           concatenate_285[0][0]            \n",
            "                                                                 dropout_304[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 4, 4, 440)    1760        concatenate_286[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 4, 4, 440)    0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 4, 4, 40)     158400      activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_305 (Dropout)           (None, 4, 4, 40)     0           conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_287 (Concatenate)   (None, 4, 4, 480)    0           concatenate_286[0][0]            \n",
            "                                                                 dropout_305[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 4, 4, 480)    1920        concatenate_287[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 4, 4, 480)    0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 4, 4, 40)     172800      activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_306 (Dropout)           (None, 4, 4, 40)     0           conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_288 (Concatenate)   (None, 4, 4, 520)    0           concatenate_287[0][0]            \n",
            "                                                                 dropout_306[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 4, 4, 520)    2080        concatenate_288[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 4, 4, 520)    0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 2, 2, 520)    0           activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 2080)         0           average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 10)           20810       flatten_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,816,730\n",
            "Trainable params: 4,786,570\n",
            "Non-trainable params: 30,160\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# checkpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath= \"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1368
        },
        "outputId": "8313c86e-c9b4-4aac-9d7d-7f703552defd",
        "executionInfo": {
          "elapsed": 6268816,
          "status": "error",
          "timestamp": 1527451164838,
          "user": {
            "displayName": "suraj bonagiri",
            "photoUrl": "//lh6.googleusercontent.com/-0F1W31o5q6E/AAAAAAAAAAI/AAAAAAAAA1c/XRzofGyVVA0/s50-c-k-no/photo.jpg",
            "userId": "117654023614571625344"
          },
          "user_tz": -330
        }
      },
      "cell_type": "code",
      "source": [
        "#1-10\n",
        "epoch = 0\n",
        "e = 10\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=e,\n",
        "                    verbose=1,\n",
        "                    initial_epoch=epoch,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 628s 13ms/step - loss: 1.5076 - acc: 0.4483 - val_loss: 1.7112 - val_acc: 0.4838\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.48380, saving model to weights-improvement-01-0.48.hdf5\n",
            "Epoch 2/10\n",
            "13952/50000 [=======>......................] - ETA: 6:54 - loss: 1.1552 - acc: 0.584350000/50000 [==============================] - 620s 12ms/step - loss: 1.0596 - acc: 0.6198 - val_loss: 1.9296 - val_acc: 0.5166\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.48380 to 0.51660, saving model to weights-improvement-02-0.52.hdf5\n",
            "Epoch 3/10\n",
            "29312/50000 [================>.............] - ETA: 3:57 - loss: 0.8666 - acc: 0.690250000/50000 [==============================] - 619s 12ms/step - loss: 0.8380 - acc: 0.7006 - val_loss: 1.0405 - val_acc: 0.6769\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.51660 to 0.67690, saving model to weights-improvement-03-0.68.hdf5\n",
            "Epoch 4/10\n",
            "33280/50000 [==================>...........] - ETA: 3:11 - loss: 0.7294 - acc: 0.743350000/50000 [==============================] - 618s 12ms/step - loss: 0.7129 - acc: 0.7482 - val_loss: 1.2930 - val_acc: 0.6436\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.67690\n",
            "Epoch 5/10\n",
            "41216/50000 [=======================>......] - ETA: 1:40 - loss: 0.6304 - acc: 0.777350000/50000 [==============================] - 618s 12ms/step - loss: 0.6283 - acc: 0.7792 - val_loss: 1.6967 - val_acc: 0.6048\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.67690\n",
            "Epoch 6/10\n",
            "43648/50000 [=========================>....] - ETA: 1:12 - loss: 0.5702 - acc: 0.801150000/50000 [==============================] - 619s 12ms/step - loss: 0.5671 - acc: 0.8019 - val_loss: 1.0605 - val_acc: 0.7053\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.67690 to 0.70530, saving model to weights-improvement-06-0.71.hdf5\n",
            "Epoch 7/10\n",
            "36992/50000 [=====================>........] - ETA: 2:29 - loss: 0.5207 - acc: 0.817550000/50000 [==============================] - 620s 12ms/step - loss: 0.5197 - acc: 0.8184 - val_loss: 0.7726 - val_acc: 0.7643\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.70530 to 0.76430, saving model to weights-improvement-07-0.76.hdf5\n",
            "Epoch 8/10\n",
            "35200/50000 [====================>.........] - ETA: 2:50 - loss: 0.4817 - acc: 0.831850000/50000 [==============================] - 620s 12ms/step - loss: 0.4799 - acc: 0.8330 - val_loss: 0.8098 - val_acc: 0.7519\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.76430\n",
            "Epoch 9/10\n",
            "41728/50000 [========================>.....] - ETA: 1:35 - loss: 0.4393 - acc: 0.847150000/50000 [==============================] - 619s 12ms/step - loss: 0.4381 - acc: 0.8470 - val_loss: 0.8874 - val_acc: 0.7676\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.76430 to 0.76760, saving model to weights-improvement-09-0.77.hdf5\n",
            "Epoch 10/10\n",
            "36352/50000 [====================>.........] - ETA: 2:36 - loss: 0.4022 - acc: 0.857350000/50000 [==============================] - 619s 12ms/step - loss: 0.4055 - acc: 0.8578 - val_loss: 1.0491 - val_acc: 0.7326\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.76760\n",
            "10000/10000 [==============================] - 53s 5ms/step\n",
            "Test loss: 1.0491465888023377\n",
            "Test accuracy: 0.7326\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3587137d9d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DNST_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     84\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m     85\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: NetworkError when attempting to fetch resource."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gHQbqoSnPDaq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "5ad1b44d-b9cc-4fe6-9456-ee8e57ba1aba",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527511475789,
          "user_tz": -330,
          "elapsed": 2068,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "#!cp *.hdf5 drive/EIP/\n",
        "#!cp *.h5 drive/EIP"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attempt_1\t\t\t  weights-improvement-30-0.85.hdf5\r\n",
            "datalab\t\t\t\t  weights-improvement-30-0.86.hdf5\r\n",
            "DNST_model.h5\t\t\t  weights-improvement-31-0.87.hdf5\r\n",
            "drive\t\t\t\t  weights-improvement-33-0.86.hdf5\r\n",
            "weights-improvement-25-0.84.hdf5  weights-improvement-39-0.87.hdf5\r\n",
            "weights-improvement-26-0.83.hdf5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0qjjdhTiu1kX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "731297f5-16ea-4e1d-d7b2-9be5162c6167",
        "executionInfo": {
          "elapsed": 6498971,
          "status": "ok",
          "timestamp": 1527462651530,
          "user": {
            "displayName": "Suraj Bonagiri",
            "photoUrl": "//lh6.googleusercontent.com/-HWIOtEIf-Ak/AAAAAAAAAAI/AAAAAAAAABM/TIMYSFACcpQ/s50-c-k-no/photo.jpg",
            "userId": "117637857141205973833"
          },
          "user_tz": -330
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('weights-improvement-09-0.77.hdf5')\n",
        "\n",
        "#10-20\n",
        "epoch = 10\n",
        "e = 20\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=e,\n",
        "                    verbose=1,\n",
        "                    initial_epoch=epoch,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 669s 13ms/step - loss: 0.4284 - acc: 0.8510 - val_loss: 1.0082 - val_acc: 0.7369\n",
            "\n",
            "Epoch 00011: val_acc improved from -inf to 0.73690, saving model to weights-improvement-11-0.74.hdf5\n",
            "Epoch 12/20\n",
            "13696/50000 [=======>......................] - ETA: 7:10 - loss: 0.3869 - acc: 0.865750000/50000 [==============================] - 639s 13ms/step - loss: 0.3957 - acc: 0.8625 - val_loss: 0.7689 - val_acc: 0.7897\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.73690 to 0.78970, saving model to weights-improvement-12-0.79.hdf5\n",
            "Epoch 13/20\n",
            "29184/50000 [================>.............] - ETA: 4:06 - loss: 0.3551 - acc: 0.874950000/50000 [==============================] - 639s 13ms/step - loss: 0.3599 - acc: 0.8740 - val_loss: 0.7729 - val_acc: 0.7882\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.78970\n",
            "Epoch 14/20\n",
            "39808/50000 [======================>.......] - ETA: 2:00 - loss: 0.3377 - acc: 0.882350000/50000 [==============================] - 639s 13ms/step - loss: 0.3370 - acc: 0.8825 - val_loss: 0.7185 - val_acc: 0.8171\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.78970 to 0.81710, saving model to weights-improvement-14-0.82.hdf5\n",
            "Epoch 15/20\n",
            "35840/50000 [====================>.........] - ETA: 2:47 - loss: 0.3113 - acc: 0.890550000/50000 [==============================] - 639s 13ms/step - loss: 0.3149 - acc: 0.8892 - val_loss: 0.9503 - val_acc: 0.7719\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.81710\n",
            "Epoch 16/20\n",
            "41856/50000 [========================>.....] - ETA: 1:36 - loss: 0.2947 - acc: 0.896050000/50000 [==============================] - 639s 13ms/step - loss: 0.2963 - acc: 0.8951 - val_loss: 0.7764 - val_acc: 0.8050\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.81710\n",
            "Epoch 17/20\n",
            "43648/50000 [=========================>....] - ETA: 1:15 - loss: 0.2703 - acc: 0.904450000/50000 [==============================] - 639s 13ms/step - loss: 0.2737 - acc: 0.9034 - val_loss: 1.0090 - val_acc: 0.7821\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.81710\n",
            "Epoch 18/20\n",
            "44160/50000 [=========================>....] - ETA: 1:09 - loss: 0.2533 - acc: 0.911650000/50000 [==============================] - 639s 13ms/step - loss: 0.2543 - acc: 0.9110 - val_loss: 0.7602 - val_acc: 0.7980\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.81710\n",
            "Epoch 19/20\n",
            "44416/50000 [=========================>....] - ETA: 1:06 - loss: 0.2414 - acc: 0.912850000/50000 [==============================] - 639s 13ms/step - loss: 0.2422 - acc: 0.9129 - val_loss: 0.9550 - val_acc: 0.7998\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.81710\n",
            "Epoch 20/20\n",
            "44416/50000 [=========================>....] - ETA: 1:06 - loss: 0.2265 - acc: 0.919650000/50000 [==============================] - 638s 13ms/step - loss: 0.2284 - acc: 0.9190 - val_loss: 0.7137 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.81710 to 0.82140, saving model to weights-improvement-20-0.82.hdf5\n",
            "10000/10000 [==============================] - 55s 5ms/step\n",
            "Test loss: 0.7136646812915802\n",
            "Test accuracy: 0.8214\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LgiKA7VuwPMg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!cp *.hdf5 drive/EIP/\n",
        "!cp *.h5 drive/EIP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzKaSUR3yv_y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d588084d-928b-4217-a468-6a924bbec7bd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527476773666,
          "user_tz": -330,
          "elapsed": 2351,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print('Using real-time data augmentation.')\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator( \n",
        "    rotation_range=90, \n",
        "    width_shift_range=0.1, \n",
        "    height_shift_range=0.1, \n",
        "    horizontal_flip=True) \n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pulM1UQiu140",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "736788ea-1ed6-4f81-dd6d-e605f6e66ad0",
        "executionInfo": {
          "elapsed": 3366457,
          "status": "ok",
          "timestamp": 1527469300970,
          "user": {
            "displayName": "Suraj Bonagiri",
            "photoUrl": "//lh6.googleusercontent.com/-HWIOtEIf-Ak/AAAAAAAAAAI/AAAAAAAAABM/TIMYSFACcpQ/s50-c-k-no/photo.jpg",
            "userId": "117637857141205973833"
          },
          "user_tz": -330
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('weights-improvement-20-0.82.hdf5')\n",
        "\n",
        "#20-25\n",
        "epoch=20\n",
        "e = 25\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=e,\n",
        "                    verbose=1,\n",
        "                    initial_epoch=epoch,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "!ls\n",
        "!cp *.hdf5 drive/EIP/\n",
        "!cp *.h5 drive/EIP"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 670s 13ms/step - loss: 0.2766 - acc: 0.9024 - val_loss: 0.7347 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00021: val_acc improved from -inf to 0.81640, saving model to weights-improvement-21-0.82.hdf5\n",
            "Epoch 22/25\n",
            "13696/50000 [=======>......................] - ETA: 7:09 - loss: 0.2579 - acc: 0.908150000/50000 [==============================] - 636s 13ms/step - loss: 0.2602 - acc: 0.9077 - val_loss: 0.7440 - val_acc: 0.8308\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.81640 to 0.83080, saving model to weights-improvement-22-0.83.hdf5\n",
            "Epoch 23/25\n",
            "29184/50000 [================>.............] - ETA: 4:05 - loss: 0.2437 - acc: 0.911950000/50000 [==============================] - 635s 13ms/step - loss: 0.2516 - acc: 0.9092 - val_loss: 0.7689 - val_acc: 0.8195\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.83080\n",
            "Epoch 24/25\n",
            "39808/50000 [======================>.......] - ETA: 2:00 - loss: 0.2347 - acc: 0.917650000/50000 [==============================] - 636s 13ms/step - loss: 0.2366 - acc: 0.9161 - val_loss: 0.6548 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.83080 to 0.84160, saving model to weights-improvement-24-0.84.hdf5\n",
            "Epoch 25/25\n",
            "35840/50000 [====================>.........] - ETA: 2:46 - loss: 0.2246 - acc: 0.919950000/50000 [==============================] - 636s 13ms/step - loss: 0.2298 - acc: 0.9179 - val_loss: 0.6695 - val_acc: 0.8442\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.84160 to 0.84420, saving model to weights-improvement-25-0.84.hdf5\n",
            "10000/10000 [==============================] - 54s 5ms/step\n",
            "Test loss: 0.6695378522396087\n",
            "Test accuracy: 0.8442\n",
            "Saved model to disk\n",
            "datalab\t\t\t\t  weights-improvement-11-0.74.hdf5\n",
            "DNST_model.h5\t\t\t  weights-improvement-12-0.79.hdf5\n",
            "drive\t\t\t\t  weights-improvement-14-0.82.hdf5\n",
            "weights-improvement-01-0.48.hdf5  weights-improvement-20-0.82.hdf5\n",
            "weights-improvement-02-0.52.hdf5  weights-improvement-21-0.82.hdf5\n",
            "weights-improvement-03-0.68.hdf5  weights-improvement-22-0.83.hdf5\n",
            "weights-improvement-06-0.71.hdf5  weights-improvement-24-0.84.hdf5\n",
            "weights-improvement-07-0.76.hdf5  weights-improvement-25-0.84.hdf5\n",
            "weights-improvement-09-0.77.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vKAiQ9llu19e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "ff9c6888-fd62-4e5c-b003-97f880b739c9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527483559526,
          "user_tz": -330,
          "elapsed": 6422302,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('weights-improvement-25-0.84.hdf5')\n",
        "#25-35\n",
        "epoch = 25\n",
        "e = 35\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=e,\n",
        "                    verbose=1,\n",
        "                    initial_epoch=epoch,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "!ls\n",
        "!cp *.hdf5 drive/EIP/\n",
        "!cp *.h5 drive/EIP"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 26/35\n",
            "50000/50000 [==============================] - 654s 13ms/step - loss: 0.2298 - acc: 0.9188 - val_loss: 0.7404 - val_acc: 0.8284\n",
            "\n",
            "Epoch 00026: val_acc improved from -inf to 0.82840, saving model to weights-improvement-26-0.83.hdf5\n",
            "Epoch 27/35\n",
            "13696/50000 [=======>......................] - ETA: 7:04 - loss: 0.2029 - acc: 0.9287"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 629s 13ms/step - loss: 0.2153 - acc: 0.9237 - val_loss: 0.9706 - val_acc: 0.7929\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.82840\n",
            "Epoch 28/35\n",
            "34944/50000 [===================>..........] - ETA: 2:55 - loss: 0.2062 - acc: 0.9278"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 629s 13ms/step - loss: 0.2103 - acc: 0.9261 - val_loss: 0.9227 - val_acc: 0.8015\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.82840\n",
            "Epoch 29/35\n",
            "41472/50000 [=======================>......] - ETA: 1:39 - loss: 0.1992 - acc: 0.9294"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 629s 13ms/step - loss: 0.1998 - acc: 0.9287 - val_loss: 0.9477 - val_acc: 0.8048\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.82840\n",
            "Epoch 30/35\n",
            "43520/50000 [=========================>....] - ETA: 1:15 - loss: 0.1961 - acc: 0.9304"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 628s 13ms/step - loss: 0.1955 - acc: 0.9305 - val_loss: 0.6155 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.82840 to 0.85670, saving model to weights-improvement-30-0.86.hdf5\n",
            "Epoch 31/35\n",
            "36864/50000 [=====================>........] - ETA: 2:33 - loss: 0.1856 - acc: 0.9347"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 630s 13ms/step - loss: 0.1871 - acc: 0.9339 - val_loss: 0.5510 - val_acc: 0.8666\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.85670 to 0.86660, saving model to weights-improvement-31-0.87.hdf5\n",
            "Epoch 32/35\n",
            "35072/50000 [====================>.........] - ETA: 2:54 - loss: 0.1782 - acc: 0.9365"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 629s 13ms/step - loss: 0.1789 - acc: 0.9367 - val_loss: 0.6797 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.86660\n",
            "Epoch 33/35\n",
            "41600/50000 [=======================>......] - ETA: 1:38 - loss: 0.1721 - acc: 0.9388"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 629s 13ms/step - loss: 0.1748 - acc: 0.9379 - val_loss: 0.8459 - val_acc: 0.8297\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.86660\n",
            "Epoch 34/35\n",
            "43520/50000 [=========================>....] - ETA: 1:15 - loss: 0.1651 - acc: 0.9414"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 628s 13ms/step - loss: 0.1655 - acc: 0.9412 - val_loss: 0.7229 - val_acc: 0.8378\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.86660\n",
            "Epoch 35/35\n",
            "44160/50000 [=========================>....] - ETA: 1:08 - loss: 0.1657 - acc: 0.9410"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 628s 13ms/step - loss: 0.1668 - acc: 0.9409 - val_loss: 0.7003 - val_acc: 0.8486\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.86660\n",
            "10000/10000 [==============================] - 52s 5ms/step\n",
            "Test loss: 0.7002615824878216\n",
            "Test accuracy: 0.8486\n",
            "Saved model to disk\n",
            "attempt_1\t\t\t  weights-improvement-26-0.83.hdf5\n",
            "datalab\t\t\t\t  weights-improvement-30-0.85.hdf5\n",
            "DNST_model.h5\t\t\t  weights-improvement-30-0.86.hdf5\n",
            "drive\t\t\t\t  weights-improvement-31-0.87.hdf5\n",
            "weights-improvement-25-0.84.hdf5  weights-improvement-33-0.86.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pVVUDfjiu2Ap",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "86968269-447c-4fa9-a806-ff7762fccf86",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527494139464,
          "user_tz": -330,
          "elapsed": 3224464,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#35-40\n",
        "epoch=35\n",
        "e = 40\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=e,\n",
        "                    verbose=1,\n",
        "                    initial_epoch=epoch,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "!ls\n",
        "!cp *.hdf5 drive/EIP/\n",
        "!cp *.h5 drive/EIP"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 36/40\n",
            "50000/50000 [==============================] - 626s 13ms/step - loss: 0.1552 - acc: 0.9450 - val_loss: 1.4790 - val_acc: 0.7479\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.86660\n",
            "Epoch 37/40\n",
            "15872/50000 [========>.....................] - ETA: 6:37 - loss: 0.1442 - acc: 0.9485"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 627s 13ms/step - loss: 0.1526 - acc: 0.9460 - val_loss: 0.7985 - val_acc: 0.8401\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.86660\n",
            "Epoch 38/40\n",
            "35712/50000 [====================>.........] - ETA: 2:45 - loss: 0.1492 - acc: 0.9461"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 627s 13ms/step - loss: 0.1528 - acc: 0.9455 - val_loss: 0.7576 - val_acc: 0.8439\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.86660\n",
            "Epoch 39/40\n",
            "41728/50000 [========================>.....] - ETA: 1:36 - loss: 0.1409 - acc: 0.9493"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 627s 13ms/step - loss: 0.1442 - acc: 0.9480 - val_loss: 0.6216 - val_acc: 0.8688\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.86660 to 0.86880, saving model to weights-improvement-39-0.87.hdf5\n",
            "Epoch 40/40\n",
            "36352/50000 [====================>.........] - ETA: 2:38 - loss: 0.1439 - acc: 0.9485"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 626s 13ms/step - loss: 0.1434 - acc: 0.9487 - val_loss: 0.7147 - val_acc: 0.8562\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.86880\n",
            "10000/10000 [==============================] - 52s 5ms/step\n",
            "Test loss: 0.7147344080418349\n",
            "Test accuracy: 0.8562\n",
            "Saved model to disk\n",
            "attempt_1\t\t\t  weights-improvement-30-0.85.hdf5\n",
            "datalab\t\t\t\t  weights-improvement-30-0.86.hdf5\n",
            "DNST_model.h5\t\t\t  weights-improvement-31-0.87.hdf5\n",
            "drive\t\t\t\t  weights-improvement-33-0.86.hdf5\n",
            "weights-improvement-25-0.84.hdf5  weights-improvement-39-0.87.hdf5\n",
            "weights-improvement-26-0.83.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IGfN6_Hdt_2l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1009
        },
        "outputId": "3722f136-4f8a-4cf3-c51e-8dbe69a04166",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527527135557,
          "user_tz": -330,
          "elapsed": 6628607,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('weights-improvement-39-0.87.hdf5')\n",
        "\n",
        "#40-50\n",
        "epoch=40\n",
        "e = 50\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=e,\n",
        "                    verbose=1,\n",
        "                    initial_epoch=epoch,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "!ls\n",
        "!cp *.hdf5 drive/EIP/\n",
        "!cp *.h5 drive/EIP"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 662s 13ms/step - loss: 0.1467 - acc: 0.9469 - val_loss: 0.7625 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00041: val_acc improved from -inf to 0.84300, saving model to weights-improvement-41-0.84.hdf5\n",
            "Epoch 42/50\n",
            "13696/50000 [=======>......................] - ETA: 7:15 - loss: 0.1226 - acc: 0.9571"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 645s 13ms/step - loss: 0.1360 - acc: 0.9516 - val_loss: 0.6692 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.84300 to 0.85960, saving model to weights-improvement-42-0.86.hdf5\n",
            "Epoch 43/50\n",
            "29184/50000 [================>.............] - ETA: 4:08 - loss: 0.1322 - acc: 0.9531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 644s 13ms/step - loss: 0.1345 - acc: 0.9520 - val_loss: 0.8009 - val_acc: 0.8440\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.85960\n",
            "Epoch 44/50\n",
            "39808/50000 [======================>.......] - ETA: 2:02 - loss: 0.1273 - acc: 0.9541"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 647s 13ms/step - loss: 0.1284 - acc: 0.9537 - val_loss: 0.8075 - val_acc: 0.8421\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.85960\n",
            "Epoch 45/50\n",
            "43008/50000 [========================>.....] - ETA: 1:23 - loss: 0.1268 - acc: 0.9547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 644s 13ms/step - loss: 0.1269 - acc: 0.9548 - val_loss: 0.7416 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.85960\n",
            "Epoch 46/50\n",
            "44032/50000 [=========================>....] - ETA: 1:11 - loss: 0.1193 - acc: 0.9581"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 642s 13ms/step - loss: 0.1209 - acc: 0.9574 - val_loss: 0.6001 - val_acc: 0.8741\n",
            "\n",
            "Epoch 00046: val_acc improved from 0.85960 to 0.87410, saving model to weights-improvement-46-0.87.hdf5\n",
            "Epoch 47/50\n",
            "36992/50000 [=====================>........] - ETA: 2:34 - loss: 0.1159 - acc: 0.9598"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 643s 13ms/step - loss: 0.1178 - acc: 0.9590 - val_loss: 0.7108 - val_acc: 0.8650\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.87410\n",
            "Epoch 48/50\n",
            "42112/50000 [========================>.....] - ETA: 1:34 - loss: 0.1154 - acc: 0.9590"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 643s 13ms/step - loss: 0.1165 - acc: 0.9588 - val_loss: 0.5952 - val_acc: 0.8740\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.87410\n",
            "Epoch 49/50\n",
            "43776/50000 [=========================>....] - ETA: 1:14 - loss: 0.1093 - acc: 0.9619"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 643s 13ms/step - loss: 0.1104 - acc: 0.9617 - val_loss: 0.7101 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.87410\n",
            "Epoch 50/50\n",
            "44288/50000 [=========================>....] - ETA: 1:08 - loss: 0.1134 - acc: 0.9588"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 643s 13ms/step - loss: 0.1138 - acc: 0.9588 - val_loss: 0.6850 - val_acc: 0.8716\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.87410\n",
            "10000/10000 [==============================] - 54s 5ms/step\n",
            "Test loss: 0.6850166329085827\n",
            "Test accuracy: 0.8716\n",
            "Saved model to disk\n",
            "attempt_1\t\t\t  weights-improvement-33-0.86.hdf5\n",
            "datalab\t\t\t\t  weights-improvement-39-0.87.hdf5\n",
            "DNST_model.h5\t\t\t  weights-improvement-41-0.82.hdf5\n",
            "drive\t\t\t\t  weights-improvement-41-0.84.hdf5\n",
            "weights-improvement-25-0.84.hdf5  weights-improvement-42-0.86.hdf5\n",
            "weights-improvement-26-0.83.hdf5  weights-improvement-42-0.87.hdf5\n",
            "weights-improvement-30-0.85.hdf5  weights-improvement-44-0.88.hdf5\n",
            "weights-improvement-30-0.86.hdf5  weights-improvement-46-0.87.hdf5\n",
            "weights-improvement-31-0.87.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4d82450b-e0e3-4a28-d5da-aac895764f1e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527519683485,
          "user_tz": -330,
          "elapsed": 80375,
          "user": {
            "displayName": "suraj b",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102683608279765749841"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('weights-improvement-44-0.88.hdf5')\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 56s 6ms/step\n",
            "Test loss: 0.6380089717403055\n",
            "Test accuracy: 0.875\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}